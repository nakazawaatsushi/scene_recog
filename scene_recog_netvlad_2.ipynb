{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate, Activation, Lambda, Subtract, Dot, Multiply\n",
    "from keras.layers import Input, Dense, Flatten, Convolution1D, RepeatVector, Add\n",
    "from keras.engine.topology import Container\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import Zeros\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.activations import softmax\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import sys, glob, math, os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from numpy.random import *\n",
    "\n",
    "ncluster = 50\n",
    "nfeature = 196\n",
    "nfeature_dim = 512\n",
    "nbatch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-ddc5f64e72b7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ddc5f64e72b7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def make_data(data,centers,gt_label)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def make_data(data,centers,gt_label)\n",
    "\n",
    "    idx = np.random.randint(0,data.shape[0],data.shape[0])\n",
    "\n",
    "    data_all = data\n",
    "    data_all2 = data[idx,:,:]\n",
    "    gt_label_all = gt_label\n",
    "    gt_label_all2 = gt_label[idx]\n",
    "    centers_all = centers\n",
    "\n",
    "    for i in range(0,19):\n",
    "        data_all = np.concatenate((data_all,data),axis=0)\n",
    "        idx = np.random.randint(0,data.shape[0],data.shape[0])\n",
    "        data_all2 = np.concatenate((data_all2,data[idx,:,:]),axis=0)\n",
    "        gt_label_all  = np.concatenate((gt_label_all,gt_label))\n",
    "        gt_label_all2 = np.concatenate((gt_label_all2,gt_label[idx]))\n",
    "        centers_all = np.concatenate((centers_all,centers), axis=0)\n",
    "        idx = np.random.randint(0,data.shape[0],data.shape[0])\n",
    "          \n",
    "    # ground truth\n",
    "    y_gt = np.zeros((data_all.shape[0]))\n",
    "\n",
    "    for i in range(0,gt_label_all.shape[0]):\n",
    "        if gt_label_all[i] == gt_label_all2[i]:\n",
    "            y_gt[i] = 1\n",
    "        else:\n",
    "            y_gt[i] = 0\n",
    "        \n",
    "    # choose positives and negatives as same samples\n",
    "    p_idx = []\n",
    "    for i in range(0,gt_label_all.shape[0]):\n",
    "        if gt_label_all[i] == gt_label_all2[i]:\n",
    "            p_idx.append(i)\n",
    "\n",
    "    n_idx = []\n",
    "    for i in range(0,gt_label_all.shape[0]):\n",
    "        if gt_label_all[i] != gt_label_all2[i]:\n",
    "            n_idx.append(i)\n",
    "\n",
    "    idx = p_idx\n",
    "    idx.extend(n_idx[0:len(p_idx)])\n",
    "\n",
    "    data_all = data_all[idx,:,:]\n",
    "    data_all2 = data_all2[idx,:,:]\n",
    "    centers_all = centers_all[idx,:,:]\n",
    "    y_gt = y_gt[idx]\n",
    "    \n",
    "    return data_all, data_all2, centers_all, y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_softmax(x):\n",
    "    y = softmax(x, axis=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transpose(x):\n",
    "    x = K.permute_dimensions(x,(1,2,0))\n",
    "    y = K.transpose(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_tensor(x,i,c):\n",
    "    # make [xi-c(1) xi-c(2) ... xi-c(n)] tensor\n",
    "    t = x[:,i,:]\n",
    "    z = K.repeat(t, ncluster)\n",
    "    z = z - c\n",
    "#    z = K.permute_dimensions(z,(0,1,2))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rep_tensor_and_mult(w,x,c,batch_size):\n",
    "    zz = K.zeros(shape=(batch_size,nfeature_dim,ncluster))\n",
    "    \n",
    "    for i in range(0,nfeature):\n",
    "        # Feature vector\n",
    "        t = x[:,i,:]\n",
    "        t = K.repeat(t, ncluster)\n",
    "        t = t - c\n",
    "        t = K.permute_dimensions(t,(1,2,0))\n",
    "        t = K.transpose(t)\n",
    "        \n",
    "        # Weight vector\n",
    "        ww = w[:,i,:]\n",
    "        z = K.repeat(ww, nfeature_dim)\n",
    "                \n",
    "        tmp = z*t\n",
    "        zz = zz + tmp\n",
    "        # K.update_add(zz,tmp)\n",
    "        #zz = zz + tmp\n",
    "        #zz = K.update_add(zz,tmp)\n",
    "    \n",
    "    return zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(y_true, y_pred): # y_true's shape=(batch_size, row, col, ch)\n",
    "    S = ncluster*nfeature_dim\n",
    "    x1 = y_pred[:,:S]\n",
    "    x2 = y_pred[:,S:]\n",
    "    z = K.batch_dot(x1,x2,axes=1)\n",
    "    z = K.abs(y_true - z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Split_and_dot(x):\n",
    "    s = K.int_shape(x)\n",
    "    x1 = x[:,:25600]\n",
    "    x2 = x[:,25600:]\n",
    "    \n",
    "    z = K.batch_dot(x1,x2,axes=1)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L1_normalize(x):\n",
    "    #x = K.l2_normalize(x, axis=1)\n",
    "    x = x / K.sum(x, axis=1, keepdims=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L2_normalize(x):\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    #x = x / K.sum(x, axis=1, keepdims=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def netvlad_model():\n",
    "    # input feature and cluster centers\n",
    "    x_input  = Input([nfeature,nfeature_dim], name='x_input')\n",
    "    x_input2 = Input([nfeature,nfeature_dim], name='x_input2') \n",
    "    c_input = Input([ncluster,nfeature_dim], name='c_input')\n",
    "    \n",
    "    # start designing BASE_LAYERS\n",
    "    conv_1 = []\n",
    "    for i in range(0,ncluster):\n",
    "        x = Convolution1D(1, 1, padding='same', use_bias=True)(x_input)\n",
    "        conv_1.append(x)\n",
    "    \n",
    "    w = Concatenate(axis=2)(conv_1)\n",
    "    w = Lambda(custom_softmax, name='cumstom_softmax')(w)\n",
    "    z = Lambda(rep_tensor_and_mult, arguments={'x': x_input,'c': c_input,'batch_size': nbatch}, name='rep_tensor_mult')(w)\n",
    "    z = Flatten()(z)\n",
    "    z = Lambda(L2_normalize)(z)\n",
    "    # end BASE_LAYERS\n",
    "    \n",
    "    # define second reference layers\n",
    "    base_layers = Container(x_input, z, name=\"base_layers\")\n",
    "    z2 = base_layers(x_input2)\n",
    "    \n",
    "    # concatenate in one list\n",
    "    z_list = []    \n",
    "    z_list.append(z)\n",
    "    z_list.append(z2)\n",
    "    \n",
    "    z_out = Concatenate()(z_list)\n",
    "    #z_out = Lambda(Split_and_dot)(z_out)\n",
    "    \n",
    "    model = Model(inputs=[x_input,x_input2,c_input], outputs=z_out)\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss=generator_loss)\n",
    "    \n",
    "#    model.summary()\n",
    " \n",
    "    return model\n",
    "#END vgg19_lower_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fc00b6a22ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetvlad_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-91af7d265ad4>\u001b[0m in \u001b[0;36mnetvlad_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cumstom_softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_tensor_and_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rep_tensor_mult'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_softmax' is not defined"
     ]
    }
   ],
   "source": [
    "model = netvlad_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"data.npy\")\n",
    "center = np.load(\"centers.npy\")\n",
    "centers = np.zeros((data.shape[0],center.shape[0],center.shape[1]))\n",
    "for i in range(0,data.shape[0]):\n",
    "    centers[i,:,:]=center\n",
    "\n",
    "me = np.load(\"mean.npy\")\n",
    "stv = np.load(\"stv.npy\")\n",
    "gt_label = np.loadtxt(\"result-frame-org.csv\",delimiter=\",\", usecols=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 196, 512)\n",
      "(184, 200, 512)\n",
      "(512,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(centers.shape)\n",
    "print(me.shape)\n",
    "print(stv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ddda0965b31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_data_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_data_all2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_centers_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv_data_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_data_all2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_centers_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_y_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_data' is not defined"
     ]
    }
   ],
   "source": [
    "t_data_all, t_data_all2, t_centers_all, t_y_gt = make_data(data,centers,gt_label)\n",
    "v_data_all, v_data_all2, v_centers_all, v_y_gt = make_data(data,centers,gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModelCheckpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-36cba06051bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cache/model_weights_{epoch:02d}.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit([t_data_all,t_data_all2,t_centers_all], t_y_gt, \n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ModelCheckpoint' is not defined"
     ]
    }
   ],
   "source": [
    "cp = ModelCheckpoint('./cache/model_weights_{epoch:02d}.h5')\n",
    "\n",
    "model.fit([t_data_all,t_data_all2,t_centers_all], t_y_gt, \n",
    "          batch_size=nbatch, \n",
    "          epochs=50, \n",
    "          verbose=1, \n",
    "          validation_data=([v_data_all,v_data_all2,v_centers_all], v_y_gt),\n",
    "          shuffle=True,\n",
    "          callbacks=[cp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.fit([data_all,data_all2,centers_all], y_gt, batch_size=nbatch, epochs=20, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('netvlad2-weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
