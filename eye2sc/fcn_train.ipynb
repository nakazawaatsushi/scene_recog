{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fcn(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv5])\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv7), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(input=inputs, output=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "==> 350 training images loaded\n",
      "==> 350 training masks loaded\n",
      "==> 70 validation images loaded\n",
      "==> 70 validation masks loaded\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    fpaths_xs_train = list_pictures_in_multidir(['..\\\\patches\\\\src\\\\'])\n",
    "    fpaths_ys_train = list_pictures_in_multidir(['..\\\\patches\\\\dst\\\\'])\n",
    "    fpaths_xs_valid = list_pictures_in_multidir(['..\\\\patches\\\\src_valid\\\\'])\n",
    "    fpaths_ys_valid = list_pictures_in_multidir(['..\\\\patches\\\\dst_valid\\\\'])\n",
    "    \n",
    "    dim_ordering ='tf' \n",
    "    dim_ordering = 'channels_first'\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    \n",
    "    # データを配列として取得\n",
    "    print('loading data...')\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, \n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, \n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False,\n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True,\n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing mean and standard deviation...\n",
      "==> mean: [ 92.09872437  85.38002014  97.14896393]\n",
      "==> std : [ 45.22496033  43.68132782  48.07133484]\n",
      "saving mean and standard deviation to stats.npy...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "    \n",
    "    fname_stats = 'stats.npy'\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 32, 224, 224)  896         input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 32, 224, 224)  9248        conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D)  (None, 32, 112, 112)  0           conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 64, 112, 112)  18496       max_pooling2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 64, 112, 112)  36928       conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D)  (None, 64, 56, 56)    0           conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 128, 56, 56)   73856       max_pooling2d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 128, 56, 56)   147584      conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D)  (None, 128, 28, 28)   0           conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 256, 28, 28)   295168      max_pooling2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 256, 28, 28)   590080      conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D)  (None, 256, 14, 14)   0           conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 512, 14, 14)   1180160     max_pooling2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 512, 14, 14)   2359808     conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D)  (None, 512, 7, 7)     0           conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 1024, 7, 7)    4719616     max_pooling2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 1024, 7, 7)    9438208     conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling2D)  (None, 1024, 14, 14)  0           conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 1536, 14, 14)  0           up_sampling2d_27[0][0]           \n",
      "                                                                   conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 512, 14, 14)   7078400     concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 512, 14, 14)   2359808     conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling2D)  (None, 512, 28, 28)   0           conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 768, 28, 28)   0           up_sampling2d_28[0][0]           \n",
      "                                                                   conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 256, 28, 28)   1769728     concatenate_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 256, 28, 28)   590080      conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling2D)  (None, 256, 56, 56)   0           conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 384, 56, 56)   0           up_sampling2d_29[0][0]           \n",
      "                                                                   conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 128, 56, 56)   442496      concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 128, 56, 56)   147584      conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_30 (UpSampling2D)  (None, 128, 112, 112) 0           conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 192, 112, 112) 0           up_sampling2d_30[0][0]           \n",
      "                                                                   conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 64, 112, 112)  110656      concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 64, 112, 112)  36928       conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_31 (UpSampling2D)  (None, 64, 224, 224)  0           conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (None, 96, 224, 224)  0           up_sampling2d_31[0][0]           \n",
      "                                                                   conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 32, 224, 224)  27680       concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 32, 224, 224)  9248        conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 32, 224, 1)    225         conv2d_168[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 31,442,881\n",
      "Trainable params: 31,442,881\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model = create_fcn(target_size)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"\n",
      "c:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "c:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_8/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_8/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c6672e3229d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# モデルを作成\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'creating model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_fcn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-1cc7da4601d9>\u001b[0m in \u001b[0;36mcreate_fcn\u001b[1;34m(input_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpool2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                                         data_format=self.data_format)\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m    215\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m    216\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                           pool_mode='max')\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3385\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'max'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3386\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3387\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3388\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   1770\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1771\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1772\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   1773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m_max_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[0;32m   1604\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   1606\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2632\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nakazawa atsushi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_8/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,64]."
     ]
    }
   ],
   "source": [
    "# 損失関数，最適化手法を定義\n",
    "adam = Adam(lr=1e-5)\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "# 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "\n",
    "    # モデルの構造を保存\n",
    "    json_string = model.to_json()\n",
    "    fpath_architecture = os.path.join(dpath_checkpoints, fname_architecture)\n",
    "    with open(fpath_architecture, 'wb') as f:\n",
    "        f.write(json_string)\n",
    "\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)\n",
    "\n",
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1,\n",
    "              shuffle=True, validation_data=(X_valid, Y_valid),\n",
    "              callbacks=[checkpointer])\n",
    "    \n",
    "    \"\"\"\n",
    "    else: # test\n",
    "        # コマンドライン引数の正否をチェック\n",
    "        assert(os.path.isfile(args.weights))\n",
    "\n",
    "        # データを配列として取得\n",
    "        print('loading data...')\n",
    "        dpath_xs_test = os.path.join(dpath_data, 'test')\n",
    "        fpaths_xs_test = list_pictures(dpath_xs_test)\n",
    "        fnames_xs_test = [os.path.basename(fpath) for fpath in fpaths_xs_test]\n",
    "        X_test = load_imgs_asarray(fpaths_xs_test, grayscale=False,\n",
    "                                   target_size=target_size,\n",
    "                                   dim_ordering=dim_ordering)\n",
    "        print('==> ' + str(len(X_test)) +  ' test images loaded')\n",
    "\n",
    "        # トレーニング時に計算した平均・標準偏差をロード\n",
    "        print('loading mean and standard deviation from ' + fname_stats + '...')\n",
    "        stats = np.load(fname_stats)\n",
    "        mean = stats['mean']\n",
    "        std = stats['std']\n",
    "        print('==> mean: ' + str(mean))\n",
    "        print('==> std : ' + str(std))\n",
    "\n",
    "        print('globally normalizing data...')\n",
    "        for i in range(3):\n",
    "            X_test[:, i] = (X_test[:, i] - mean[i]) / std[i]\n",
    "        print('==> done')\n",
    "\n",
    "        # モデルを作成\n",
    "        # （model_from_json()を使って保存してある構造を読み込むことも可能）\n",
    "        print('creating model...')\n",
    "        model = create_fcn(target_size)\n",
    "        model.summary()\n",
    "\n",
    "        # 学習済みの重みをロード\n",
    "        fpath_weights = os.path.realpath(args.weights)\n",
    "        print('loading weights from ' + fpath_weights)\n",
    "        model.load_weights(fpath_weights)\n",
    "        print('==> done')\n",
    "\n",
    "        # テストを開始\n",
    "        outputs = model.predict(X_test)\n",
    "\n",
    "        # 出力を画像として保存\n",
    "        dpath_outputs = os.path.join(dpath_this, dname_outputs)\n",
    "        if not os.path.isdir(dpath_outputs):\n",
    "            os.mkdir(dpath_outputs)\n",
    "\n",
    "        print('saving outputs as images...')\n",
    "        for i, array in enumerate(outputs):\n",
    "            array = np.where(array > 0.5, 1, 0) # 二値に変換\n",
    "            array = array.astype(np.float32)\n",
    "            img_out = array_to_img(array, dim_ordering)\n",
    "            fpath_out = os.path.join(dpath_outputs, fnames_xs_test[i])\n",
    "            img_out.save(fpath_out)\n",
    "        print('==> done')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
