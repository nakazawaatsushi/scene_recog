{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv5])\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv7), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(input=inputs, output=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................==> 2071 training images loaded\n",
      "==> 2071 training masks loaded\n",
      "==> 212 validation images loaded\n",
      "==> 212 validation masks loaded\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    fpaths_xs_train = list_pictures_in_multidir(['./dataset/train/image/', \n",
    "                                                 './dataset/train/image-aug/'])\n",
    "    fpaths_ys_train = list_pictures_in_multidir(['./dataset/train/gt/', \n",
    "                                                 './dataset/train/gt-aug/'])\n",
    "    fpaths_xs_valid = list_pictures_in_multidir(['./dataset/valid/image/', \n",
    "                                                 './dataset/valid/image-aug/'])\n",
    "    fpaths_ys_valid = list_pictures_in_multidir(['./dataset/valid/gt/', \n",
    "                                                 './dataset/valid/gt-aug/'])\n",
    "#    fpaths_xs_train = list_pictures_in_multidir(['./data-scene/train/', \n",
    "#                                                 './data-scene/train-aug/'])\n",
    "#    fpaths_ys_train = list_pictures_in_multidir(['./data-scene/train_mask/', \n",
    "#                                                 './data-scene/train_mask-aug/'])\n",
    "#    fpaths_xs_valid = list_pictures_in_multidir(['./data-scene/valid/', \n",
    "#                                                 './data-scene/valid-aug'])\n",
    "#    fpaths_ys_valid = list_pictures_in_multidir(['./data-scene/valid_mask', \n",
    "#                                                 './data-scene/valid_mask-aug/'])\n",
    "    \n",
    "    #dim_ordering ='tf' \n",
    "    dim_ordering = 'channels_first'\n",
    "    target_size = (224, 224)\n",
    "    \n",
    "    # データを配列として取得\n",
    "    print('loading data...')\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, \n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, \n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False,\n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True,\n",
    "                                target_size=target_size, dim_ordering=dim_ordering)\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing mean and standard deviation...\n",
      "==> mean: [ 211.48577881  174.08840942  191.61517334]\n",
      "==> std : [ 59.50221252  58.8382988   59.77029419]\n",
      "saving mean and standard deviation to stats.npy...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "    \n",
    "    fname_stats = 'stats.npy'\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')\n",
    "    \n",
    "    print(mean.shape)\n",
    "    print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 32, 224, 224)  896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 32, 224, 224)  9248        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 32, 112, 112)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 64, 112, 112)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 64, 112, 112)  36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 56, 56)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 128, 56, 56)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 128, 56, 56)   147584      conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 128, 28, 28)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 256, 28, 28)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 256, 28, 28)   590080      conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 256, 14, 14)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 512, 14, 14)   1180160     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 512, 14, 14)   2359808     conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 512, 7, 7)     0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 1024, 7, 7)    4719616     max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 1024, 7, 7)    9438208     conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 1024, 14, 14)  0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 1536, 14, 14)  0           up_sampling2d_1[0][0]            \n",
      "                                                                   conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 512, 14, 14)   7078400     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 512, 14, 14)   2359808     conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 512, 28, 28)   0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 768, 28, 28)   0           up_sampling2d_2[0][0]            \n",
      "                                                                   conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 256, 28, 28)   1769728     concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 256, 28, 28)   590080      conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 256, 56, 56)   0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 384, 56, 56)   0           up_sampling2d_3[0][0]            \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 128, 56, 56)   442496      concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 128, 56, 56)   147584      conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 128, 112, 112) 0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 192, 112, 112) 0           up_sampling2d_4[0][0]            \n",
      "                                                                   conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 64, 112, 112)  110656      concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 64, 112, 112)  36928       conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)   (None, 64, 224, 224)  0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 96, 224, 224)  0           up_sampling2d_5[0][0]            \n",
      "                                                                   conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 32, 224, 224)  27680       concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 32, 224, 224)  9248        conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 1, 224, 224)   33          conv2d_22[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 31,442,689\n",
      "Trainable params: 31,442,689\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.5/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model = create_fcn(target_size)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数，最適化手法を定義\n",
    "adam = Adam(lr=1e-5)\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "# 構造・重みを保存するディレクトリーの有無を確認\n",
    "dpath_checkpoints = './checkpoints/'\n",
    "if not os.path.isdir(dpath_checkpoints):\n",
    "    os.mkdir(dpath_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの構造を保存\n",
    "json_string = model.to_json()\n",
    "fname_architecture = 'fcn.json'\n",
    "fpath_architecture = os.path.join(dpath_checkpoints, fname_architecture)\n",
    "with open(fpath_architecture, 'w', encoding='utf8') as f:\n",
    "    f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2071, 3, 224, 224)\n",
      "(2071, 1, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 2071 samples, validate on 212 samples\n",
      "Epoch 1/300\n",
      "2071/2071 [==============================] - 180s - loss: -0.4684 - dice_coef: 0.4684 - val_loss: -0.7406 - val_dice_coef: 0.7406\n",
      "Epoch 2/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.7207 - dice_coef: 0.7207 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 3/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.7655 - dice_coef: 0.7655 - val_loss: -0.7152 - val_dice_coef: 0.7152\n",
      "Epoch 4/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.7926 - dice_coef: 0.7926 - val_loss: -0.6733 - val_dice_coef: 0.6733\n",
      "Epoch 5/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.7940 - dice_coef: 0.7940 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 6/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8215 - dice_coef: 0.8215 - val_loss: -0.7796 - val_dice_coef: 0.7796\n",
      "Epoch 7/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8350 - dice_coef: 0.8350 - val_loss: -0.7380 - val_dice_coef: 0.7380\n",
      "Epoch 8/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.6725 - val_dice_coef: 0.6725\n",
      "Epoch 9/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.6375 - val_dice_coef: 0.6375\n",
      "Epoch 10/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.7410 - val_dice_coef: 0.7410\n",
      "Epoch 11/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.6122 - val_dice_coef: 0.6122\n",
      "Epoch 12/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.6171 - val_dice_coef: 0.6171\n",
      "Epoch 13/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.6020 - val_dice_coef: 0.6020\n",
      "Epoch 14/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.6496 - val_dice_coef: 0.6496\n",
      "Epoch 15/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.6440 - val_dice_coef: 0.6440\n",
      "Epoch 16/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.6390 - val_dice_coef: 0.6390\n",
      "Epoch 17/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.6826 - val_dice_coef: 0.6826\n",
      "Epoch 18/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.6992 - val_dice_coef: 0.6992\n",
      "Epoch 19/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.6743 - val_dice_coef: 0.6743\n",
      "Epoch 20/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9061 - dice_coef: 0.9061 - val_loss: -0.7422 - val_dice_coef: 0.7422\n",
      "Epoch 21/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9137 - dice_coef: 0.9137 - val_loss: -0.7098 - val_dice_coef: 0.7098\n",
      "Epoch 22/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.7457 - val_dice_coef: 0.7457\n",
      "Epoch 23/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.7463 - val_dice_coef: 0.7463\n",
      "Epoch 24/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9245 - dice_coef: 0.9245 - val_loss: -0.7761 - val_dice_coef: 0.7761\n",
      "Epoch 25/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9255 - dice_coef: 0.9255 - val_loss: -0.7821 - val_dice_coef: 0.7821\n",
      "Epoch 26/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.7704 - val_dice_coef: 0.7704\n",
      "Epoch 27/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9294 - dice_coef: 0.9294 - val_loss: -0.7942 - val_dice_coef: 0.7942\n",
      "Epoch 28/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9254 - dice_coef: 0.9254 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "Epoch 29/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9341 - dice_coef: 0.9341 - val_loss: -0.8277 - val_dice_coef: 0.8277\n",
      "Epoch 30/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9332 - dice_coef: 0.9332 - val_loss: -0.8141 - val_dice_coef: 0.8141\n",
      "Epoch 31/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9383 - dice_coef: 0.9383 - val_loss: -0.7928 - val_dice_coef: 0.7928\n",
      "Epoch 32/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9388 - dice_coef: 0.9388 - val_loss: -0.8104 - val_dice_coef: 0.8104\n",
      "Epoch 33/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9402 - dice_coef: 0.9402 - val_loss: -0.8096 - val_dice_coef: 0.8096\n",
      "Epoch 34/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9432 - dice_coef: 0.9432 - val_loss: -0.7897 - val_dice_coef: 0.7897\n",
      "Epoch 35/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9448 - dice_coef: 0.9448 - val_loss: -0.8094 - val_dice_coef: 0.8094\n",
      "Epoch 36/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9448 - dice_coef: 0.9448 - val_loss: -0.8001 - val_dice_coef: 0.8001\n",
      "Epoch 37/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9457 - dice_coef: 0.9457 - val_loss: -0.8166 - val_dice_coef: 0.8166\n",
      "Epoch 38/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9473 - dice_coef: 0.9473 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 39/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9486 - dice_coef: 0.9486 - val_loss: -0.8068 - val_dice_coef: 0.8068\n",
      "Epoch 40/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9503 - dice_coef: 0.9503 - val_loss: -0.8085 - val_dice_coef: 0.8085\n",
      "Epoch 41/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9504 - dice_coef: 0.9504 - val_loss: -0.7959 - val_dice_coef: 0.7959\n",
      "Epoch 42/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9505 - dice_coef: 0.9505 - val_loss: -0.8496 - val_dice_coef: 0.8496\n",
      "Epoch 43/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9494 - dice_coef: 0.9494 - val_loss: -0.8029 - val_dice_coef: 0.8029\n",
      "Epoch 44/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9518 - dice_coef: 0.9518 - val_loss: -0.8221 - val_dice_coef: 0.8221\n",
      "Epoch 45/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9540 - dice_coef: 0.9540 - val_loss: -0.7935 - val_dice_coef: 0.7935\n",
      "Epoch 46/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9541 - dice_coef: 0.9541 - val_loss: -0.8127 - val_dice_coef: 0.8127\n",
      "Epoch 47/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9540 - dice_coef: 0.9540 - val_loss: -0.8121 - val_dice_coef: 0.8121\n",
      "Epoch 48/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9545 - dice_coef: 0.9545 - val_loss: -0.8127 - val_dice_coef: 0.8127\n",
      "Epoch 49/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9568 - dice_coef: 0.9568 - val_loss: -0.7971 - val_dice_coef: 0.7971\n",
      "Epoch 50/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9563 - dice_coef: 0.9563 - val_loss: -0.8126 - val_dice_coef: 0.8126\n",
      "Epoch 51/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9568 - dice_coef: 0.9568 - val_loss: -0.8143 - val_dice_coef: 0.8143\n",
      "Epoch 52/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9590 - dice_coef: 0.9590 - val_loss: -0.8042 - val_dice_coef: 0.8042\n",
      "Epoch 53/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9587 - dice_coef: 0.9587 - val_loss: -0.8161 - val_dice_coef: 0.8161\n",
      "Epoch 54/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9576 - dice_coef: 0.9576 - val_loss: -0.8316 - val_dice_coef: 0.8316\n",
      "Epoch 55/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9574 - dice_coef: 0.9574 - val_loss: -0.8085 - val_dice_coef: 0.8085\n",
      "Epoch 56/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9588 - dice_coef: 0.9588 - val_loss: -0.8167 - val_dice_coef: 0.8167\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2071/2071 [==============================] - 176s - loss: -0.9582 - dice_coef: 0.9582 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 58/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9585 - dice_coef: 0.9585 - val_loss: -0.8204 - val_dice_coef: 0.8204\n",
      "Epoch 59/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9587 - dice_coef: 0.9587 - val_loss: -0.8285 - val_dice_coef: 0.8285\n",
      "Epoch 60/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9608 - dice_coef: 0.9608 - val_loss: -0.8036 - val_dice_coef: 0.8036\n",
      "Epoch 61/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9595 - dice_coef: 0.9595 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 62/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9601 - dice_coef: 0.9601 - val_loss: -0.8161 - val_dice_coef: 0.8161\n",
      "Epoch 63/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9598 - dice_coef: 0.9598 - val_loss: -0.7813 - val_dice_coef: 0.7813\n",
      "Epoch 64/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9612 - dice_coef: 0.9612 - val_loss: -0.8350 - val_dice_coef: 0.8350\n",
      "Epoch 65/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9618 - dice_coef: 0.9618 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 66/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9619 - dice_coef: 0.9619 - val_loss: -0.8406 - val_dice_coef: 0.8406\n",
      "Epoch 67/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9617 - dice_coef: 0.9617 - val_loss: -0.8305 - val_dice_coef: 0.8305\n",
      "Epoch 68/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9609 - dice_coef: 0.9609 - val_loss: -0.8193 - val_dice_coef: 0.8193\n",
      "Epoch 69/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9611 - dice_coef: 0.9611 - val_loss: -0.8230 - val_dice_coef: 0.8230\n",
      "Epoch 70/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9610 - dice_coef: 0.9610 - val_loss: -0.8363 - val_dice_coef: 0.8363\n",
      "Epoch 71/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9605 - dice_coef: 0.9605 - val_loss: -0.8090 - val_dice_coef: 0.8090\n",
      "Epoch 72/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9630 - dice_coef: 0.9630 - val_loss: -0.8248 - val_dice_coef: 0.8248\n",
      "Epoch 73/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9629 - dice_coef: 0.9629 - val_loss: -0.8139 - val_dice_coef: 0.8139\n",
      "Epoch 74/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9636 - dice_coef: 0.9636 - val_loss: -0.8237 - val_dice_coef: 0.8237\n",
      "Epoch 75/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9625 - dice_coef: 0.9625 - val_loss: -0.8272 - val_dice_coef: 0.8272\n",
      "Epoch 76/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9618 - dice_coef: 0.9618 - val_loss: -0.8122 - val_dice_coef: 0.8122\n",
      "Epoch 77/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9636 - dice_coef: 0.9636 - val_loss: -0.8082 - val_dice_coef: 0.8082\n",
      "Epoch 78/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9632 - dice_coef: 0.9632 - val_loss: -0.8001 - val_dice_coef: 0.8001\n",
      "Epoch 79/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9641 - dice_coef: 0.9641 - val_loss: -0.8272 - val_dice_coef: 0.8272\n",
      "Epoch 80/300\n",
      "2071/2071 [==============================] - 177s - loss: -0.9632 - dice_coef: 0.9632 - val_loss: -0.8253 - val_dice_coef: 0.8253\n",
      "Epoch 81/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9644 - dice_coef: 0.9644 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 82/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9635 - dice_coef: 0.9635 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 83/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9643 - dice_coef: 0.9643 - val_loss: -0.8255 - val_dice_coef: 0.8255\n",
      "Epoch 84/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9642 - dice_coef: 0.9642 - val_loss: -0.8309 - val_dice_coef: 0.8309\n",
      "Epoch 85/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9638 - dice_coef: 0.9638 - val_loss: -0.8406 - val_dice_coef: 0.8406\n",
      "Epoch 86/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9640 - dice_coef: 0.9640 - val_loss: -0.8255 - val_dice_coef: 0.8255\n",
      "Epoch 87/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9642 - dice_coef: 0.9642 - val_loss: -0.8503 - val_dice_coef: 0.8503\n",
      "Epoch 88/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9626 - dice_coef: 0.9626 - val_loss: -0.8387 - val_dice_coef: 0.8387\n",
      "Epoch 89/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9630 - dice_coef: 0.9630 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 90/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9649 - dice_coef: 0.9649 - val_loss: -0.8213 - val_dice_coef: 0.8213\n",
      "Epoch 91/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9640 - dice_coef: 0.9640 - val_loss: -0.8189 - val_dice_coef: 0.8189\n",
      "Epoch 92/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9655 - dice_coef: 0.9655 - val_loss: -0.8376 - val_dice_coef: 0.8376\n",
      "Epoch 93/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9656 - dice_coef: 0.9656 - val_loss: -0.8287 - val_dice_coef: 0.8287\n",
      "Epoch 94/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9651 - dice_coef: 0.9651 - val_loss: -0.8427 - val_dice_coef: 0.8427\n",
      "Epoch 95/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9652 - dice_coef: 0.9652 - val_loss: -0.8086 - val_dice_coef: 0.8086\n",
      "Epoch 96/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9641 - dice_coef: 0.9641 - val_loss: -0.8248 - val_dice_coef: 0.8248\n",
      "Epoch 97/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9642 - dice_coef: 0.9642 - val_loss: -0.8372 - val_dice_coef: 0.8372\n",
      "Epoch 98/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9657 - dice_coef: 0.9657 - val_loss: -0.8273 - val_dice_coef: 0.8273\n",
      "Epoch 99/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9655 - dice_coef: 0.9655 - val_loss: -0.8129 - val_dice_coef: 0.8129\n",
      "Epoch 100/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9645 - dice_coef: 0.9645 - val_loss: -0.8316 - val_dice_coef: 0.8316\n",
      "Epoch 101/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9656 - dice_coef: 0.9656 - val_loss: -0.8138 - val_dice_coef: 0.8138\n",
      "Epoch 102/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9659 - dice_coef: 0.9659 - val_loss: -0.8315 - val_dice_coef: 0.8315\n",
      "Epoch 103/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9655 - dice_coef: 0.9655 - val_loss: -0.8294 - val_dice_coef: 0.8294\n",
      "Epoch 104/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9664 - dice_coef: 0.9664 - val_loss: -0.8131 - val_dice_coef: 0.8131\n",
      "Epoch 105/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9658 - dice_coef: 0.9658 - val_loss: -0.8269 - val_dice_coef: 0.8269\n",
      "Epoch 106/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9652 - dice_coef: 0.9652 - val_loss: -0.8421 - val_dice_coef: 0.8421\n",
      "Epoch 107/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9675 - dice_coef: 0.9675 - val_loss: -0.8314 - val_dice_coef: 0.8314\n",
      "Epoch 108/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9665 - dice_coef: 0.9665 - val_loss: -0.8249 - val_dice_coef: 0.8249\n",
      "Epoch 109/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9671 - dice_coef: 0.9671 - val_loss: -0.8338 - val_dice_coef: 0.8338\n",
      "Epoch 110/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9656 - dice_coef: 0.9656 - val_loss: -0.8252 - val_dice_coef: 0.8252\n",
      "Epoch 111/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9653 - dice_coef: 0.9653 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 112/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9665 - dice_coef: 0.9665 - val_loss: -0.8305 - val_dice_coef: 0.8305\n",
      "Epoch 113/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9664 - dice_coef: 0.9664 - val_loss: -0.8385 - val_dice_coef: 0.8385\n",
      "Epoch 114/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2071/2071 [==============================] - 176s - loss: -0.9659 - dice_coef: 0.9659 - val_loss: -0.8408 - val_dice_coef: 0.8408\n",
      "Epoch 115/300\n",
      "2071/2071 [==============================] - 175s - loss: -0.9672 - dice_coef: 0.9672 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 116/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9661 - dice_coef: 0.9661 - val_loss: -0.8379 - val_dice_coef: 0.8379\n",
      "Epoch 117/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9667 - dice_coef: 0.9667 - val_loss: -0.8370 - val_dice_coef: 0.8370\n",
      "Epoch 118/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9673 - dice_coef: 0.9673 - val_loss: -0.8351 - val_dice_coef: 0.8351\n",
      "Epoch 119/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9667 - dice_coef: 0.9667 - val_loss: -0.8278 - val_dice_coef: 0.8278\n",
      "Epoch 120/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9671 - dice_coef: 0.9671 - val_loss: -0.8444 - val_dice_coef: 0.8444\n",
      "Epoch 121/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9669 - dice_coef: 0.9669 - val_loss: -0.8273 - val_dice_coef: 0.8273\n",
      "Epoch 122/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9662 - dice_coef: 0.9662 - val_loss: -0.8356 - val_dice_coef: 0.8356\n",
      "Epoch 123/300\n",
      "2071/2071 [==============================] - 176s - loss: -0.9669 - dice_coef: 0.9669 - val_loss: -0.8143 - val_dice_coef: 0.8143\n",
      "Epoch 124/300\n",
      "  75/2071 [>.............................] - ETA: 165s - loss: -0.9653 - dice_coef: 0.9653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0eb8117cba68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model.fit(X_train, Y_train, batch_size=5, epochs=300, verbose=1, \n\u001b[0;32m----> 9\u001b[0;31m           shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 重みを保存するためのオブジェクトを用意\n",
    "fname_weights = 'model_weights_{epoch:02d}.h5'\n",
    "fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)\n",
    "\n",
    "# トレーニングを開始\n",
    "print('start training...')\n",
    "model.fit(X_train, Y_train, batch_size=5, epochs=300, verbose=1, \n",
    "          shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
