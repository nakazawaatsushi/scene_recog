{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ拡張テスト\n",
    "# http://aidiary.hatenablog.com/entry/20161212/1481549365\n",
    "# https://keras.io/preprocessing/image/\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import sys, glob, math, os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image sizes\n",
    "img_rows, img_cols = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imgs(dir,normalize=0):\n",
    "    # load image data from dir\n",
    "\n",
    "    data = []\n",
    "    fname = []\n",
    "    path  = dir + '/*.png'\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        print('reading %s'%format(fl))\n",
    "\n",
    "        img = cv2.imread(fl)\n",
    "        img = cv2.resize(img, (img_rows,img_cols))\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        if normalize == 1:\n",
    "            img -= np.mean(img)\n",
    "            img /= np.std(img)\n",
    "\n",
    "        data.append(img)\n",
    "        fname.append(fl)\n",
    "\n",
    "    data = np.array(data,dtype=np.uint8)\n",
    "\n",
    "    return data, fname\n",
    "# end of load_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ./dataset/valid/image/watanabe0243.png\n",
      "reading ./dataset/valid/image/watanabe0287.png\n",
      "reading ./dataset/valid/image/watanabe0346.png\n",
      "reading ./dataset/valid/image/watanabe0414.png\n",
      "reading ./dataset/valid/image/watanabe0451.png\n",
      "reading ./dataset/valid/image/watanabe0495.png\n",
      "reading ./dataset/valid/image/watanabe0574.png\n",
      "reading ./dataset/valid/image/watanabe0638.png\n",
      "reading ./dataset/valid/image/watanabe0699.png\n",
      "reading ./dataset/valid/image/watanabe0750.png\n",
      "reading ./dataset/valid/image/watanabe0794.png\n",
      "reading ./dataset/valid/image/watanabe0862.png\n",
      "reading ./dataset/valid/gt/watanabe0243.png\n",
      "reading ./dataset/valid/gt/watanabe0287.png\n",
      "reading ./dataset/valid/gt/watanabe0346.png\n",
      "reading ./dataset/valid/gt/watanabe0414.png\n",
      "reading ./dataset/valid/gt/watanabe0451.png\n",
      "reading ./dataset/valid/gt/watanabe0495.png\n",
      "reading ./dataset/valid/gt/watanabe0574.png\n",
      "reading ./dataset/valid/gt/watanabe0638.png\n",
      "reading ./dataset/valid/gt/watanabe0699.png\n",
      "reading ./dataset/valid/gt/watanabe0750.png\n",
      "reading ./dataset/valid/gt/watanabe0794.png\n",
      "reading ./dataset/valid/gt/watanabe0862.png\n"
     ]
    }
   ],
   "source": [
    "#imgs, name = load_imgs('./dataset/train/image')\n",
    "#imgs2, name2 = load_imgs('./dataset/train/gt')\n",
    "#dst_dir = './dataset/train/image-aug'\n",
    "#dst_dir2 = './dataset/train/gt-aug'\n",
    "imgs, name = load_imgs('./dataset/valid/image')\n",
    "imgs2, name2 = load_imgs('./dataset/valid/gt')\n",
    "dst_dir = './dataset/valid/image-aug'\n",
    "dst_dir2 = './dataset/valid/gt-aug'\n",
    "os.mkdir(dst_dir)\n",
    "os.mkdir(dst_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(featurewise_center=False,\n",
    "                     featurewise_std_normalization=False,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.2,\n",
    "                     height_shift_range=0.2,\n",
    "                     zoom_range=0.3,\n",
    "                     channel_shift_range=0.,\n",
    "                     cval=0.,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True )\n",
    "\n",
    "#data_gen_args = dict(rotation_range=90.)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(imgs, augment=True)\n",
    "mask_datagen.fit(imgs2, augment=True)\n",
    "\n",
    "g  = image_datagen.flow(imgs, batch_size=1, seed=1)\n",
    "g2 = mask_datagen.flow(imgs2, batch_size=1, seed=1)\n",
    "\n",
    "n = 0\n",
    "\n",
    "for i in range(200):\n",
    "    x = g.next()\n",
    "#    cv2.imshow('batch', x[0].astype(np.uint8))\n",
    "    x2 = g2.next()\n",
    "#    cv2.imshow('batch2', x2[0].astype(np.uint8))\n",
    "    cv2.imwrite('%s/%05d.jpg'%(dst_dir,n),x[0].astype(np.uint8))\n",
    "    cv2.imwrite('%s/%05d.jpg'%(dst_dir2,n),x2[0].astype(np.uint8))\n",
    "    n = n + 1\n",
    "#    cv2.waitKey(5)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
